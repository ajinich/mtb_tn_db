{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load new matrices: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '../../data/standardized_data/'\n",
    "file_log2fc = os.path.join(path_data, 'result_logfc_matrix_2023_02_20_CC_BxD_processed.csv')\n",
    "file_qval = os.path.join(path_data, 'result_qval_matrix_2023_02_20_CC_BxD_processed.csv')\n",
    "file_bin = os.path.join(path_data, 'result_bin_matrix_2023_02_20_CC_BxD_processed.csv')\n",
    "\n",
    "file_SI = '../../data/SI_datasets/SI_bin.csv'\n",
    "\n",
    "df_log2fc = pd.read_csv(file_log2fc)\n",
    "df_qval = pd.read_csv(file_qval)\n",
    "df_bin = pd.read_csv(file_bin)\n",
    "\n",
    "df_old = pd.read_csv(file_SI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4055, 147)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_new = df_bin.columns.tolist()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing all screens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_col_desc = '../../data/meta_data/column_descriptors_standardized_w_mBio_101823.xlsx'\n",
    "df_col_desc = pd.read_excel(file_col_desc)\n",
    "\n",
    "# We are excluding two publications from this analysis since we processed the datasets directly with C. Smith\n",
    "df_col_desc = df_col_desc[~df_col_desc.first_author.isin(['Smith', 'Meade'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map = list(zip(df_col_desc.column_ID_SI.values, df_col_desc.column_ID_2.values))\n",
    "col_map_pairs = [cm for cm in col_map if cm[0] in df_old.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PENDING: increase this set of mapped screens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2003A_Sassetti', nan),\n",
       " ('2003B_Sassetti', nan),\n",
       " ('2005_Rengarajan', nan),\n",
       " ('2006_Joshi_GI_1', nan),\n",
       " ('2006_Joshi_GI_2', nan),\n",
       " ('2011_Griffin_2', 'griffin_cholesterol_vs_griffin_glycerol'),\n",
       " ('2012_Zhang', nan),\n",
       " ('2013_Zhang_1A', 'zhang_wt_mouse_d10_vs_zhang_input_library'),\n",
       " ('2013_Zhang_1B', 'zhang_wt_mouse_d45_vs_zhang_input_library'),\n",
       " ('2013_Zhang_2', 'zhang_mhcii_mouse_d45_vs_zhang_wt_mouse_d45'),\n",
       " ('2013_Zhang_3A', 'zhang_Tyloxapol_pH_6.5_vs_zhang_Tyloxapol_pH_4.5'),\n",
       " ('2013_Zhang_3B', 'zhang_Tyloxapol_pH_6.5_vs_zhang_pcit_pH_4.5'),\n",
       " ('2013_Zhang_3C', 'zhang_DETA-NO_pH_7.0_vs_zhang_pH_7.0_no_NO_control'),\n",
       " ('2013_Zhang_3D', 'zhang_Trp_Rescue_vs_zhang_in_vitro_control_Rescue'),\n",
       " ('2015_Kieser_GI_1', 'kieser_dPonA1_vs_mbio_H37Rv'),\n",
       " ('2015_Kieser_GI_2', nan),\n",
       " ('2015_Kieser_GI_3', nan),\n",
       " ('2015_Mendum', nan),\n",
       " ('2016_Nambi', 'nambi_2015_ctpC_vs_nambi_2015_wt'),\n",
       " ('2016_Korte', 'korte_2016_otsa_trehalose_vs_korte_2016_otsa_7h9'),\n",
       " ('2017B_DeJesus_1A', nan),\n",
       " ('2017B_DeJesus_1B', nan),\n",
       " ('2017B_DeJesus_1C', nan),\n",
       " ('2017_Xu_1A', 'xu_van_16_vs_xu_van_0'),\n",
       " ('2017_Xu_1B', 'xu_rif_4_vs_xu_rif_0'),\n",
       " ('2017_Xu_1C', 'xu_inh_02_vs_xu_inh_0'),\n",
       " ('2017_Xu_1D', 'xu_emb_2.5_vs_xu_emb_0'),\n",
       " ('2017_Xu_1E', 'xu_mero_2.5_vs_xu_mero_0'),\n",
       " ('2017_Mishra_1', 'mishra_C3H_vs_mishra_B6'),\n",
       " ('2017_Mishra_2', 'mishra_NOS2_vs_mishra_B6'),\n",
       " ('2018_Carey_1A', 'carey_621_vs_carey_rv'),\n",
       " ('2018_Carey_1B', 'carey_630_vs_carey_rv'),\n",
       " ('2018_Carey_1C', 'carey_631_vs_carey_rv'),\n",
       " ('2018_Carey_1D', 'carey_632_vs_carey_rv'),\n",
       " ('2018_Carey_1E', 'carey_641_vs_carey_rv'),\n",
       " ('2018_Carey_1F', 'carey_662_vs_carey_rv'),\n",
       " ('2018_Carey_1G', 'carey_663_vs_carey_rv'),\n",
       " ('2018_Carey_1H', 'carey_667_vs_carey_rv'),\n",
       " ('2018_Rittershaus_1B', 'ritterhaus_hypoxia_H3_vs_ritterhaus_hypoxia_input'),\n",
       " ('2018_Rittershaus_1A', 'ritterhaus_hypoxia_H6_vs_ritterhaus_hypoxia_input')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_map_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map_pairs = [cm for cm in col_map if type(cm[0])==str and type(cm[1])==str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_map_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which screens are we missing to pair up with the new dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_map_missing = [cm for cm in col_map if type(cm[0])!=str or type(cm[1])!=str]\n",
    "df_col_map_missing = pd.DataFrame()\n",
    "df_col_map_missing['SI_name'] = [cm[0] for cm in col_map_missing]\n",
    "df_col_map_missing['standardized_name'] = [cm[1] for cm in col_map_missing]\n",
    "df_col_map_missing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Also store the column names for your old dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col_names_old = pd.DataFrame()\n",
    "df_col_names_old['old_DB_names'] = df_old.columns\n",
    "\n",
    "file_col_names_old = '../../dep/data/column_names_old_08022020.xlsx'\n",
    "df_col_names_old.to_excel(file_col_names_old, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check for the screens for which you have a column name mapping (old-to-new datasets:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old_col = df_old[['Rv_ID', '2013_Zhang_1A']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2011_Griffin_2', 'griffin_cholesterol_vs_griffin_glycerol')\n",
      "('2013_Zhang_1A', 'zhang_wt_mouse_d10_vs_zhang_input_library')\n",
      "('2013_Zhang_1B', 'zhang_wt_mouse_d45_vs_zhang_input_library')\n",
      "('2013_Zhang_2', 'zhang_mhcii_mouse_d45_vs_zhang_wt_mouse_d45')\n",
      "('2013_Zhang_3A', 'zhang_Tyloxapol_pH_6.5_vs_zhang_Tyloxapol_pH_4.5')\n",
      "('2013_Zhang_3B', 'zhang_Tyloxapol_pH_6.5_vs_zhang_pcit_pH_4.5')\n",
      "('2013_Zhang_3C', 'zhang_DETA-NO_pH_7.0_vs_zhang_pH_7.0_no_NO_control')\n",
      "('2013_Zhang_3D', 'zhang_Trp_Rescue_vs_zhang_in_vitro_control_Rescue')\n",
      "('2015_Kieser_GI_1', 'kieser_dPonA1_vs_mbio_H37Rv')\n",
      "('2016_Nambi', 'nambi_2015_ctpC_vs_nambi_2015_wt')\n",
      "('2016_Korte', 'korte_2016_otsa_trehalose_vs_korte_2016_otsa_7h9')\n",
      "('2017_Xu_1A', 'xu_van_16_vs_xu_van_0')\n",
      "('2017_Xu_1B', 'xu_rif_4_vs_xu_rif_0')\n",
      "('2017_Xu_1C', 'xu_inh_02_vs_xu_inh_0')\n",
      "('2017_Xu_1D', 'xu_emb_2.5_vs_xu_emb_0')\n",
      "('2017_Xu_1E', 'xu_mero_2.5_vs_xu_mero_0')\n",
      "('2017_Mishra_1', 'mishra_C3H_vs_mishra_B6')\n",
      "('2017_Mishra_2', 'mishra_NOS2_vs_mishra_B6')\n",
      "('2018_Carey_1A', 'carey_621_vs_carey_rv')\n",
      "('2018_Carey_1B', 'carey_630_vs_carey_rv')\n",
      "('2018_Carey_1C', 'carey_631_vs_carey_rv')\n",
      "('2018_Carey_1D', 'carey_632_vs_carey_rv')\n",
      "('2018_Carey_1E', 'carey_641_vs_carey_rv')\n",
      "('2018_Carey_1F', 'carey_662_vs_carey_rv')\n",
      "('2018_Carey_1G', 'carey_663_vs_carey_rv')\n",
      "('2018_Carey_1H', 'carey_667_vs_carey_rv')\n",
      "('2018_Rittershaus_1B', 'ritterhaus_hypoxia_H3_vs_ritterhaus_hypoxia_input')\n",
      "('2018_Rittershaus_1A', 'ritterhaus_hypoxia_H6_vs_ritterhaus_hypoxia_input')\n"
     ]
    }
   ],
   "source": [
    "list_num_both_CES = []\n",
    "list_num_both_nonCES = []\n",
    "list_num_CES_old_nonCES_new = []\n",
    "list_num_nonCES_old_CES_new = []\n",
    "\n",
    "for cols in col_map_pairs:\n",
    "    print(cols)\n",
    "    df_bin_col = df_bin[['Rv_ID', cols[1]]].copy()\n",
    "    df_old_col = df_old[['Rv_ID', cols[0]]].copy()\n",
    "    df_bin_both = df_bin_col.merge(df_old_col, how = 'inner', on = 'Rv_ID')\n",
    "\n",
    "    num_both_CES = df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==1) ].shape[0]\n",
    "    num_both_nonCES = df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==0) ].shape[0]\n",
    "    num_CES_old_nonCES_new = df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==0) ].shape[0]\n",
    "    num_nonCES_old_CES_new = df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==1) ].shape[0]\n",
    "\n",
    "    list_num_both_CES.append(num_both_CES)\n",
    "    list_num_both_nonCES.append(num_both_nonCES)\n",
    "    list_num_CES_old_nonCES_new.append(num_CES_old_nonCES_new)\n",
    "    list_num_nonCES_old_CES_new.append(num_nonCES_old_CES_new)\n",
    "    \n",
    "df_map = pd.DataFrame()\n",
    "\n",
    "df_map['screen_old_ID'] = [col[0] for col in col_map_pairs]\n",
    "df_map['screen_new_ID'] = [col[1] for col in col_map_pairs]\n",
    "\n",
    "df_map['CE_consensus'] = list_num_both_CES\n",
    "df_map['notCE_consensus'] = list_num_both_nonCES\n",
    "df_map['CE_SI_notCE_standardized'] = list_num_CES_old_nonCES_new\n",
    "df_map['notCE_SI_CE_standardized'] = list_num_nonCES_old_CES_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_old_ID               2011_Griffin_22013_Zhang_1A2013_Zhang_1B2013_Z...\n",
       "screen_new_ID               griffin_cholesterol_vs_griffin_glycerolzhang_w...\n",
       "CE_consensus                                                             1157\n",
       "notCE_consensus                                                        107952\n",
       "CE_SI_notCE_standardized                                                 1205\n",
       "notCE_SI_CE_standardized                                                 1292\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus = 1157 + 107952\n",
    "non_consensus = 1205 + 1292\n",
    "total = consensus + non_consensus\n",
    "\n",
    "frac_consensus = consensus / total\n",
    "frac_non_consensus = non_consensus / total\n",
    "\n",
    "np.round(frac_non_consensus, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "CE_consensus = 1157\n",
    "CE_SI_notCE_standardized = 1205\n",
    "notCE_SI_CE_standardized = 1292\n",
    "CE_all = CE_consensus + CE_SI_notCE_standardized + notCE_SI_CE_standardized\n",
    "frac_CE_concensus = CE_consensus / CE_all\n",
    "frac_CE_nonconcensus = (CE_SI_notCE_standardized + notCE_SI_CE_standardized) / CE_all\n",
    "\n",
    "print(np.round(frac_CE_concensus, 2))\n",
    "\n",
    "print(np.round(frac_CE_nonconcensus, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = '../../data/sanity_check_09012020.csv'\n",
    "file_out_xls = '../../data/sanity_check_09012020.xlsx'\n",
    "\n",
    "df_map.to_csv(file_out, index = False)\n",
    "df_map.to_excel(file_out_xls, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dig into more detail for a few subset of screens:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLUTE database TnSeq screens: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_map_pairs_FLUTE = [cm for cm in col_map_pairs if 'Rv' in cm[0] or 'marP' in cm[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_FLUTE = '/home/adrian/Documents/repos/mtb_tn_db/data/SI_datasets/FLUTE_KO_TnSeq/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_num_both_CES = []\n",
    "list_num_both_nonCES = []\n",
    "list_num_CES_old_nonCES_new = []\n",
    "list_num_nonCES_old_CES_new = []\n",
    "\n",
    "for cols in col_map_pairs_FLUTE:\n",
    "    file_SI = os.path.join(path_FLUTE, 'H37Rv_'+cols[0]+'.xlsx')\n",
    "    df_SI = pd.read_excel(file_SI)\n",
    "    \n",
    "    df_SI.loc[ (df_SI['p-adj'] <= 0.05) & (df_SI['log2FC'].abs() >= 1), cols[0]]=1\n",
    "    df_SI.loc[ df_SI['p-adj'] > 0.05, cols[0]]= 0\n",
    "    df_SI.loc[ df_SI['log2FC'].abs() < 1, cols[0]]= 0\n",
    "    df_SI = df_SI[['Rv_ID', 'Name', cols[0]]]\n",
    "    \n",
    "    df_bin_col = df_bin[['Rv_ID', cols[1]]].copy()\n",
    "    df_bin_both = df_SI.merge(df_bin_col, how = 'inner', on = 'Rv_ID')\n",
    "\n",
    "    num_both_CES = df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==1) ].shape[0]\n",
    "    num_both_nonCES = df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==0) ].shape[0]\n",
    "    num_CES_old_nonCES_new = df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==0) ].shape[0]\n",
    "    num_nonCES_old_CES_new = df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==1) ].shape[0]\n",
    "\n",
    "    list_num_both_CES.append(num_both_CES)\n",
    "    list_num_both_nonCES.append(num_both_nonCES)\n",
    "    list_num_CES_old_nonCES_new.append(num_CES_old_nonCES_new)\n",
    "    list_num_nonCES_old_CES_new.append(num_nonCES_old_CES_new)\n",
    "    \n",
    "df_map = pd.DataFrame()\n",
    "\n",
    "df_map['screen_old_ID'] = [col[0] for col in col_map_pairs_FLUTE]\n",
    "df_map['screen_new_ID'] = [col[1] for col in col_map_pairs_FLUTE]\n",
    "\n",
    "df_map['both_CES'] = list_num_both_CES\n",
    "df_map['both_nonCES'] = list_num_both_nonCES\n",
    "df_map['CES_old_nonCES_new'] = list_num_CES_old_nonCES_new\n",
    "df_map['nonCES_old_CES_new'] = list_num_nonCES_old_CES_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why are the two datasets so different? \n",
    "* Did Michael use a different control screen?\n",
    "* Where did those FLUTE files come from? \n",
    "    * They come from the .dat files I downloaded directly from FLUTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Griffing cholesterol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = col_map[0]\n",
    "df_bin_col = df_bin[['Rv_ID', cols[1]]].copy()\n",
    "df_old_col = df_old[['Rv_ID', cols[0]]].copy()\n",
    "df_bin_both = df_bin_col.merge(df_old_col, how = 'inner', on = 'Rv_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CES_old_nonCES_new = df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==0) ]\n",
    "df_nonCES_old_CES_new = df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==1) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the gene names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_mbio = '../../data/SI_datasets/2017A_DeJesus_Iorger/table_1.xlsx'\n",
    "df_mbio = pd.read_excel(file_mbio)\n",
    "df_mbio = df_mbio[['Rv_ID', 'Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CES_old_nonCES_new_wNames = df_CES_old_nonCES_new.merge(df_mbio, how = 'inner', on = 'Rv_ID')\n",
    "df_CES_old_nonCES_new_wNames = df_CES_old_nonCES_new_wNames[['Rv_ID', 'Name', 'griffin_cholesterol_vs_griffin_glycerol', '2011_Griffin_2']]\n",
    "\n",
    "file_out = '../../dep/data/sanity_check_griffin_CES_OLD_nonCES_NEW.csv'\n",
    "df_CES_old_nonCES_new_wNames.to_csv(file_out, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonCES_old_CES_new_wNames = df_nonCES_old_CES_new.merge(df_mbio, how = 'inner', on = 'Rv_ID')\n",
    "df_nonCES_old_CES_new_wNames = df_nonCES_old_CES_new_wNames[['Rv_ID', 'Name', 'griffin_cholesterol_vs_griffin_glycerol', '2011_Griffin_2']]\n",
    "\n",
    "file_out = '../../dep/data/sanity_check_griffin_nonCES_OLD_CES_NEW.csv'\n",
    "df_nonCES_old_CES_new_wNames.to_csv(file_out, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CES_old_nonCES_new_wNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korte 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [cm for cm in col_map if 'Korte' in cm[0]][0]\n",
    "df_bin_col = df_bin[['Rv_ID', cols[1]]].copy()\n",
    "df_old_col = df_old[['Rv_ID', cols[0]]].copy()\n",
    "df_bin_both = df_bin_col.merge(df_old_col, how = 'inner', on = 'Rv_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CES in the old dataset, but not the new one: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==0) ].Rv_ID.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Carey datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Carey et al. SI file on excluded repetitive regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_temp = '../../dep/data/'\n",
    "file_rep = os.path.join(path_temp, 'Carey_S1_Table.xlsx')\n",
    "df_rep = pd.read_excel(file_rep)\n",
    "df_rep.rename(columns = {'Rv Number': 'Rv_ID'}, inplace = True)\n",
    "df_rep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleted genes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_del = os.path.join(path_temp, 'Carey_S2_Table.xlsx')\n",
    "xl = pd.ExcelFile(file_del)\n",
    "sheets = xl.sheet_names  # see all sheet names\n",
    "dict_df_del = {}\n",
    "for sheet in sheets:\n",
    "    df_temp =  xl.parse(sheet)\n",
    "    df_temp.rename(columns = {'Rv Number': 'Rv_ID'}, inplace = True)\n",
    "    dict_df_del[sheet] = df_temp # read a specific sheet to DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicated regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rv_id_num = df_bin[['Rv_ID']].copy()\n",
    "rv_num = [ rv[2:].strip('c').strip('A').strip('B') for rv in df_rv_id_num.Rv_ID.values]\n",
    "df_rv_id_num['rv_num'] = rv_num\n",
    "df_rv_id_num.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_dup = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(PENDING): Explain what is this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dup_temp_num = [str(i) for i in range(3219, 3429)]\n",
    "list_dup_temp_rv = df_rv_id_num[df_rv_id_num.rv_num.isin(list_dup_temp_num)].Rv_ID.tolist()\n",
    "dict_list_dup['621'] = list_dup_temp_rv\n",
    "dict_list_dup['631'] = list_dup_temp_rv\n",
    "dict_list_dup['632'] = list_dup_temp_rv\n",
    "\n",
    "list_dup_temp_num = [str(i) for i in range(3188, 3429)]\n",
    "list_dup_temp_rv = df_rv_id_num[df_rv_id_num.rv_num.isin(list_dup_temp_num)].Rv_ID.tolist()\n",
    "dict_list_dup['662'] = list_dup_temp_rv\n",
    "dict_list_dup['667'] = list_dup_temp_rv\n",
    "\n",
    "dict_list_dup['630'] = []\n",
    "dict_list_dup['641'] = []\n",
    "dict_list_dup['663'] = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare old Carey results vs. new Carey results: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load older carey datasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_old = [col for col in df_old.columns if 'Carey' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_new = [col for col in df_bin.columns if 'carey_rv' in col]\n",
    "# cols_new = [col for col in df_bin.columns if 'carey' in col and 'mbio' in col]\n",
    "col_map = list(zip(cols_old, cols_new))\n",
    "col_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I exclude genes in the repetitive regions list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_num_both_CES = []\n",
    "list_num_both_nonCES = []\n",
    "list_num_CES_old_nonCES_new = []\n",
    "list_num_nonCES_old_CES_new = []\n",
    "\n",
    "for cols in col_map:\n",
    "    key_strain = cols[1].split('_')[1]\n",
    "    \n",
    "    df_bin_col = df_bin[['Rv_ID', cols[1]]].copy()\n",
    "    df_old_col = df_old[['Rv_ID', cols[0]]].copy()\n",
    "    \n",
    "    df_bin_both = df_bin_col.merge(df_old_col, how = 'inner', on = 'Rv_ID')\n",
    "    \n",
    "    # excluding repetitive genes (same across all clinical strains)\n",
    "    df_bin_both = df_bin_both[~df_bin_both.Rv_ID.isin(df_rep.Rv_ID)]\n",
    "    \n",
    "    # excluding deleted genes (strain specific)\n",
    "    df_del = dict_df_del[key_strain]\n",
    "    df_bin_both = df_bin_both[~df_bin_both.Rv_ID.isin(df_del.Rv_ID)]\n",
    "    print('Excluded', df_del.shape[0], 'genes deleted in strain:', key_strain )\n",
    "    \n",
    "    # excluding genes in duplicated regions (same across all clinical strains)\n",
    "    list_dup = dict_list_dup[key_strain]\n",
    "    df_bin_both = df_bin_both[~df_bin_both.Rv_ID.isin(list_dup)]\n",
    "    print('Excluded', len(list_dup), 'genes in duplicated region of strain:', key_strain, '\\n' )\n",
    "    \n",
    "    #####\n",
    "    file_out = os.path.join('../../dep/data/', cols[1]+'.xlsx')\n",
    "    writer = pd.ExcelWriter(file_out, engine='xlsxwriter')\n",
    "    df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==0) ].to_excel(writer, sheet_name = 'CES_old_nonCES_new', index = False)\n",
    "    df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==1) ].to_excel(writer, sheet_name = 'nonCES_old_CES_new', index = False)\n",
    "    writer.save()\n",
    "\n",
    "    num_both_CES = df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==1) ].shape[0]\n",
    "    num_both_nonCES = df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==0) ].shape[0]\n",
    "    num_CES_old_nonCES_new = df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==0) ].shape[0]\n",
    "    num_nonCES_old_CES_new = df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==1) ].shape[0]\n",
    "\n",
    "    list_num_both_CES.append(num_both_CES)\n",
    "    list_num_both_nonCES.append(num_both_nonCES)\n",
    "    list_num_CES_old_nonCES_new.append(num_CES_old_nonCES_new)\n",
    "    list_num_nonCES_old_CES_new.append(num_nonCES_old_CES_new)\n",
    "    \n",
    "df_map = pd.DataFrame()\n",
    "df_map['screen'] = [col[1] for col in col_map]\n",
    "df_map['both_CES'] = list_num_both_CES\n",
    "df_map['num_both_nonCES'] = list_num_both_nonCES\n",
    "df_map['num_CES_old_nonCES_new'] = list_num_CES_old_nonCES_new\n",
    "df_map['num_nonCES_old_CES_new'] = list_num_nonCES_old_CES_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = '../../dep/data/sanity_check_Carey_no_reps_09_2020.csv'\n",
    "df_map.to_csv(file_out, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08/01/2020 from Michael: \n",
    "#### \"comparing one of the conditions, with different flags for the resampling (e.g. LOESS, ignoring N/C terminal sites), which may explain discrepancies.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_temp = '../../data/standardized_data/'\n",
    "file_663_1 = os.path.join(path_data_temp, 'result_resampling_carey_663_vs_carey_rv_LOESS.txt')\n",
    "file_663_2 = os.path.join(path_data_temp, 'result_resampling_carey_663_vs_carey_rv_LOESS_term15.txt')\n",
    "file_663_3 = os.path.join(path_data_temp, 'result_resampling_carey_663_vs_carey_rv_LOESS_term15_2.txt')\n",
    "\n",
    "list_files = [file_663_1, file_663_2, file_663_3]\n",
    "\n",
    "list_file_names = ['663_'+f.split('rv_')[-1].split('.')[0] for f in list_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with one dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_bin(file, col):\n",
    "    \n",
    "    df = pd.read_csv(file, sep = '\\t', skiprows=[0, 1, 2, 3, 4, 5])\n",
    "    df.rename(columns = {'#Orf':'Rv_ID'}, inplace=True)\n",
    "    df = df[['Rv_ID', 'log2FC', 'Adj. p-value']]\n",
    "\n",
    "    df_qvals = df[['Rv_ID', 'Adj. p-value']].copy()\n",
    "    df_qvals.rename(columns = {'Adj. p-value': col}, inplace = True)\n",
    "    df_log2fc = df[['Rv_ID', 'log2FC']].copy()\n",
    "    df_log2fc.rename(columns = {'log2FC': col}, inplace = True)\n",
    "    df_bin = df_qvals.copy()\n",
    "\n",
    "    # binarize\n",
    "    # set thresholds\n",
    "    qval_thresh = 0.05\n",
    "    log2fc_tresh = 1\n",
    "    # binarize\n",
    "    df_bin.loc[ (df_qvals[col] <= qval_thresh) & (df_log2fc[col].abs() >= log2fc_tresh), col ] = 1\n",
    "    df_bin.loc[ (df_qvals[col] > qval_thresh), col ] = 0  \n",
    "    df_bin.loc[(df_log2fc[col].abs() < log2fc_tresh), col] = 0\n",
    "    \n",
    "    return df_bin, df_log2fc, df_qvals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = list_files[0]\n",
    "list_num_both_CES = []\n",
    "list_num_both_nonCES = []\n",
    "list_num_CES_old_nonCES_new = []\n",
    "list_num_nonCES_old_CES_new = []\n",
    "col = cols[-1]\n",
    "\n",
    "for i in range(len(list_files)):\n",
    "    file = list_files[i]\n",
    "    print(file)\n",
    "    df_bin, df_log2fc, df_qvals = file_to_bin(file, col)\n",
    "    # Compare SI data vs. Michael's new data:\n",
    "\n",
    "    key_strain = cols[1].split('_')[1]\n",
    "    df_bin_col = df_bin[['Rv_ID', cols[1]]].copy()\n",
    "    df_old_col = df_old[['Rv_ID', cols[0]]].copy()\n",
    "    df_bin_both = df_bin_col.merge(df_old_col, how = 'inner', on = 'Rv_ID')\n",
    "\n",
    "    # excluding repetitive genes (same across all clinical strains)\n",
    "    df_bin_both = df_bin_both[~df_bin_both.Rv_ID.isin(df_rep.Rv_ID)]\n",
    "\n",
    "    # excluding deleted genes (strain specific)\n",
    "    df_del = dict_df_del[key_strain]\n",
    "    df_bin_both = df_bin_both[~df_bin_both.Rv_ID.isin(df_del.Rv_ID)]\n",
    "    print('Excluded', df_del.shape[0], 'genes deleted in strain:', key_strain )\n",
    "\n",
    "    # excluding genes in duplicated regions (same across all clinical strains)\n",
    "    list_dup = dict_list_dup[key_strain]\n",
    "    df_bin_both = df_bin_both[~df_bin_both.Rv_ID.isin(list_dup)]\n",
    "    print('Excluded', len(list_dup), 'genes in duplicated region of strain:', key_strain, '\\n' )\n",
    "    \n",
    "    #####\n",
    "    file_out = os.path.join('../../dep/data/', list_file_names[i]+'.xlsx')\n",
    "    writer = pd.ExcelWriter(file_out, engine='xlsxwriter')\n",
    "    df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==0) ].to_excel(writer, sheet_name = 'CES_old_nonCES_new', index = False)\n",
    "    df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==1) ].to_excel(writer, sheet_name = 'nonCES_old_CES_new', index = False)\n",
    "    writer.save()\n",
    "\n",
    "    num_both_CES = df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==1) ].shape[0]\n",
    "    num_both_nonCES = df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==0) ].shape[0]\n",
    "    num_CES_old_nonCES_new = df_bin_both[ (df_bin_both[cols[0]]==1) & (df_bin_both[cols[1]]==0) ].shape[0]\n",
    "    num_nonCES_old_CES_new = df_bin_both[ (df_bin_both[cols[0]]==0) & (df_bin_both[cols[1]]==1) ].shape[0]\n",
    "    \n",
    "    list_num_both_CES.append(num_both_CES)\n",
    "    list_num_both_nonCES.append(num_both_nonCES)\n",
    "    list_num_CES_old_nonCES_new.append(num_CES_old_nonCES_new)\n",
    "    list_num_nonCES_old_CES_new.append(num_nonCES_old_CES_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map = pd.DataFrame()\n",
    "df_map['screen'] = list_file_names\n",
    "df_map['both_CES'] = list_num_both_CES\n",
    "df_map['num_both_nonCES'] = list_num_both_nonCES\n",
    "df_map['num_CES_old_nonCES_new'] = list_num_CES_old_nonCES_new\n",
    "df_map['num_nonCES_old_CES_new'] = list_num_nonCES_old_CES_new\n",
    "\n",
    "file_out = '../../dep/data/sanity_check_Carey_663_08012020.csv'\n",
    "df_map.to_csv(file_out, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
